Of course. Here is a unified implementation specification based on the provided plans, structured for a development team. It synthesizes the details from all versions into a single, coherent guide, prioritizing the principles laid out in your final draft.

***

## Implementation Spec: Affine Reboot

This document outlines the plan to rebuild the Affine subnet from the ground up. The current codebase will be deleted and replaced with a new, minimal implementation built on three core pillars: verifiable environments, duel-based evaluation, and independent validator sampling with shared evidence.

### 1. Guiding Principles & Design Goals

*   **Determinism & Verifiability:** Every evaluation must be reproducible from a public `challenge_id`. All verdicts must be auditable by any third party.
*   **Minimalism:** The codebase should have a small surface area, minimal dependencies, and clear, concise functions. Complexity is actively avoided.
*   **Exploit Resistance:** The design must mitigate cheating through cryptographic commitments, deterministic verification, and alignment with Bittensor's built-in security features.
*   **Simplicity & Maintainability:** The architecture should be easy to understand, test, and extend.

### 2. Repository Structure & Cleanup

The first step is a complete repository overhaul. **All existing modules are to be deleted**, including `AgentGym`, Pareto dominance logic, and round-robin samplers. The new, minimal structure will be:

```
affine/
  core/
    types.py           # Dataclasses for all core objects (Sample, Block, etc.)
    rng.py             # Seeded random number generation (e.g., from challenge_id)
    wilson.py          # Wilson score interval calculation helpers
    hashing.py         # Hashing functions (e.g., blake3) for blocks and samples
  envs/                # Gymnasium-style, verifiable environments
    base.py            # BaseEnv class with the required verification interface
    tictactoe.py       # Tic-Tac-Toe v0 (multi-turn)
    mult8.py           # 8x8 Digit Multiplication v0 (single-turn)
  duel/
    # Logic for contender-vs-champion evaluation
    sequential.py      # Single-env duel with Wilson stopping
    aggregate.py       # Multi-env aggregation with early stopping
  validators/
    sampler.py         # Independent sampling loop
    blocks.py          # Building, signing, and chaining evidence blocks
    merge.py           # Merging peer blocks and calculating VTrust
    weights.py         # Winner-takes-all weight setting logic
  miners/
    client.py          # Thin client for querying miner models via Chutes
  cli.py               # Entry points: `af validate`, `af duel`, etc.
  pyproject.toml
```

### 3. Core Data Types (`core/types.py`)

Define immutable dataclasses for all primary data structures.

```python
@dataclass(frozen=True)
class Verdict:
    ok: bool
    reason: str = ""

@dataclass(frozen=True)
class Sample:
    env_id: str
    challenge_id: str
    miner_id: str
    role: str  # 'champion' or 'contender'
    prompt: str
    response: str
    info: dict # Metadata from env.reset()
    verdict: Verdict
    request_id: str | None = None # e.g., Chutes invocation ID
    elapsed_ms: float

@dataclass(frozen=True)
class BlockHeader:
    prev_hash: str
    block_index: int
    timestamp: int
    validator_hotkey: str
    merkle_root: str
    signature: str

@dataclass(frozen=True)
class Block:
    header: BlockHeader
    samples: list[Sample]
```

### 4. Pillar 1: Deterministic Environments

All environments must be procedurally generated, deterministic, and verifiable.

#### 4.1. Common Environment Contract (`envs/base.py`)

*   **Interface:** All environments must inherit from `gymnasium.Env`.
*   **Seeding:** The `reset(seed: int)` method must use the seed to derive all randomness for the episode. The `seed` itself is derived deterministically from a `challenge_id`.
*   **Metadata:** The `info` dictionary returned by `reset` must contain the public `challenge_id` and any other metadata needed for external verification.
*   **Verification:** A pure class method `verify(prompt, response, info) -> Verdict` must exist to deterministically score a given interaction without running the full environment.

#### 4.2. Initial Environments

1.  **`tictactoe-v0` (Multi-turn)**
    *   **Task:** An agent plays one side against a perfect minimax opponent from a deterministic starting position generated by the seed.
    *   **Observation:** A representation of the 3x3 board state.
    *   **Action:** A `Discrete(9)` action space for placing a mark.
    *   **Reward:** +1 for win, 0 for draw, -1 for loss.
    *   **Verification:** `verify()` reconstructs the game from the transcript and checks if the moves are legal and the final score is correct.

2.  **`mult8-v0` (Single-turn)**
    *   **Task:** The agent is prompted to multiply two 8-digit numbers. The numbers are generated from the seed.
    *   **Observation:** The prompt string, e.g., `"Compute 12345678 * 87654321"`.
    *   **Action:** An integer response.
    *   **Reward:** +1 if the integer is exactly correct, 0 otherwise.
    *   **Verification:** `verify()` parses the integer from the response and compares it to the ground truth product.

### 5. Pillar 2: Duel-Based Evaluation

The evaluation system is rebuilt around a "king-of-the-hill" duel mechanism.

#### 5.1. Single-Environment Duel (`duel/sequential.py`)

*   **Logic:** A `contender` is evaluated against the current `champion` on a single environment.
*   **Stopping Condition:** Use the **Wilson score interval** to estimate the contender's true win rate \( p \). Stop sampling for this environment as soon as one of the following conditions is met:
    1.  The **lower bound** of the confidence interval for \( p \) is greater than `ratio_to_beat`. (**Contender Wins**)
    2.  The **upper bound** of the confidence interval for \( p \) is less than `ratio_to_beat`. (**Champion Holds**)
    3.  A maximum sample budget is reached. (**Inconclusive**)
*   **Default:** Use a 95% confidence interval. `ratio_to_beat` starts at `0.5 + Îµ`.

#### 5.2. Multi-Environment Aggregation (`duel/aggregate.py`)

*   **Logic:** Duels for all environments run in parallel. A global decision is made with early stopping.
*   **Goal:** The contender must win a strict majority of environments, defined as beating the champion in at least \( \lceil (N+K)/(2N) \cdot N \rceil \) of the \( N \) total environments, where \( K \) is a small integer margin (e.g., \(K=1\)).
*   **Early Stopping:** The global duel stops as soon as:
    1.  The contender has won enough environments to meet the majority threshold.
    2.  The contender has lost enough environments that it can no longer possibly meet the threshold.

#### 5.3. Adaptive "Ratio to Beat"

*   **Initial State:** A new contender only needs to prove it's better than the champion (`ratio_to_beat > 0.5`).
*   **Ratchet on Win:** If a contender wins and becomes the new champion, the `ratio_to_beat` is updated. It is set to the **geometric mean** of the empirical win rates (`wins/total`) from each environment the contender won.
*   **Decay:** This new, higher `ratio_to_beat` decays exponentially back towards `0.5` over a fixed period (e.g., 7 days) to prevent permanent lock-in and ensure the frontier remains competitive.
    \[ \text{ratio}(t) \leftarrow 0.5 + (\text{ratio}_{\text{peak}} - 0.5) \cdot e^{-\lambda \Delta t} \]

### 6. Pillar 3: Validator Workflow

Validators sample independently but pool their evidence to reach a consensus.

#### 6.1. Independent Sampling (`validators/sampler.py`)

*   Each validator runs its own loop, generating `challenge_id`s, querying the champion and contender miners (via Chutes), and recording the full `Sample` transcript.

#### 6.2. Evidence Blocks (`validators/blocks.py`)

*   Validators batch `Sample` objects into `Block`s.
*   Each block header contains a hash of the previous block's header (`prev_hash`), forming a tamper-evident, hash-chained log for that validator.
*   The header is signed with the validator's hotkey.
*   Blocks are published to a shared, pluggable storage backend (e.g., S3, Google Cloud Storage, or a simple HTTP endpoint).

#### 6.3. Merging & VTrust (`validators/merge.py`)

*   Validators periodically fetch the latest blocks from their peers.
*   They verify the block signatures and hash chains.
*   **VTrust** for a given validator *v* is calculated based on the accuracy of their reported `Verdict`s compared to the consensus verdict for the same `challenge_id`s across all other validators. Validators with invalid blocks or unverifiable claims are heavily penalized.

#### 6.4. Weight Setting (`validators/weights.py`)

*   The global duel result is re-calculated using the union of all valid samples from all validators, weighted by each validator's VTrust.
*   The system is **winner-takes-all**. The miner who wins the global duel receives 100% of the weight (or `1.0`). All other miners receive `0.0`.
*   Weights are set on-chain via Bittensor, respecting the Yuma Consensus / commit-reveal mechanism.

### 7. Command Line Interface (`cli.py`)

Provide a minimal set of commands for operation.

*   `af validate`: Runs the main validator loop (sampling, block creation, merging, and weight setting).
*   `af duel <champ_uid> <cont_uid>`: Runs a local duel for debugging purposes.
*   `af env run <env_id>`: Runs a single instance of an environment to test its determinism.
